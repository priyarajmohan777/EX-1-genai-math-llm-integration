{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "99f1f979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“¦ Install required packages (only run once per environment)\n",
    "!pip install langchain langchain-google-genai python-dotenv google-generativeai --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f4d823b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volume using local function: 188193.97\n",
      "Gemini response: 189660.80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Load environment variables\n",
    "_ = load_dotenv(find_dotenv())\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "# Configure Gemini API\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "# Define function to calculate cylinder volume\n",
    "def calculate_cylinder_volume(radius, height):\n",
    "    if radius <= 0 or height <= 0:\n",
    "        return \"Radius and height must be positive numbers.\"\n",
    "    volume = math.pi * (radius ** 2) * height\n",
    "    return round(volume, 2)\n",
    "\n",
    "# Function to interact with Gemini\n",
    "def chat_with_gemini(prompt, radius, height):\n",
    "    model = genai.GenerativeModel(\"models/gemini-1.5-flash-latest\")\n",
    "\n",
    "    # Including the \"function-like\" behavior manually\n",
    "    response = model.generate_content([\n",
    "        f\"{prompt}\\nRadius: {radius}, Height: {height}\",\n",
    "        \"Please just return the final volume rounded to 2 decimal places. Don't explain anything.\"\n",
    "    ])\n",
    "    \n",
    "    return response.text\n",
    "\n",
    "# Input from user\n",
    "radius = float(input(\"Enter the radius of the cylinder: \"))\n",
    "height = float(input(\"Enter the height of the cylinder: \"))\n",
    "\n",
    "# Prompt to Gemini (just to mimic the behavior)\n",
    "prompt = \"Calculate the volume of a cylinder.\"\n",
    "\n",
    "# You can either let Gemini respond, or directly call the function\n",
    "# To mimic OpenAI-style function-calling, let's use our local function:\n",
    "volume = calculate_cylinder_volume(radius, height)\n",
    "print(\"Volume using local function:\", volume)\n",
    "\n",
    "# Or if you want to test Gemini's own response:\n",
    "gemini_result = chat_with_gemini(prompt, radius, height)\n",
    "print(\"Gemini response:\", gemini_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c2ec7bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/embedding-gecko-001\n",
      "models/gemini-1.0-pro-vision-latest\n",
      "models/gemini-pro-vision\n",
      "models/gemini-1.5-pro-latest\n",
      "models/gemini-1.5-pro-002\n",
      "models/gemini-1.5-pro\n",
      "models/gemini-1.5-flash-latest\n",
      "models/gemini-1.5-flash\n",
      "models/gemini-1.5-flash-002\n",
      "models/gemini-1.5-flash-8b\n",
      "models/gemini-1.5-flash-8b-001\n",
      "models/gemini-1.5-flash-8b-latest\n",
      "models/gemini-2.5-pro-exp-03-25\n",
      "models/gemini-2.5-pro-preview-03-25\n",
      "models/gemini-2.5-flash-preview-04-17\n",
      "models/gemini-2.5-flash-preview-05-20\n",
      "models/gemini-2.5-flash\n",
      "models/gemini-2.5-flash-preview-04-17-thinking\n",
      "models/gemini-2.5-flash-lite-preview-06-17\n",
      "models/gemini-2.5-pro-preview-05-06\n",
      "models/gemini-2.5-pro-preview-06-05\n",
      "models/gemini-2.5-pro\n",
      "models/gemini-2.0-flash-exp\n",
      "models/gemini-2.0-flash\n",
      "models/gemini-2.0-flash-001\n",
      "models/gemini-2.0-flash-exp-image-generation\n",
      "models/gemini-2.0-flash-lite-001\n",
      "models/gemini-2.0-flash-lite\n",
      "models/gemini-2.0-flash-preview-image-generation\n",
      "models/gemini-2.0-flash-lite-preview-02-05\n",
      "models/gemini-2.0-flash-lite-preview\n",
      "models/gemini-2.0-pro-exp\n",
      "models/gemini-2.0-pro-exp-02-05\n",
      "models/gemini-exp-1206\n",
      "models/gemini-2.0-flash-thinking-exp-01-21\n",
      "models/gemini-2.0-flash-thinking-exp\n",
      "models/gemini-2.0-flash-thinking-exp-1219\n",
      "models/gemini-2.5-flash-preview-tts\n",
      "models/gemini-2.5-pro-preview-tts\n",
      "models/learnlm-2.0-flash-experimental\n",
      "models/gemma-3-1b-it\n",
      "models/gemma-3-4b-it\n",
      "models/gemma-3-12b-it\n",
      "models/gemma-3-27b-it\n",
      "models/gemma-3n-e4b-it\n",
      "models/embedding-001\n",
      "models/text-embedding-004\n",
      "models/gemini-embedding-exp-03-07\n",
      "models/gemini-embedding-exp\n",
      "models/aqa\n",
      "models/imagen-3.0-generate-002\n",
      "models/veo-2.0-generate-001\n",
      "models/gemini-2.5-flash-preview-native-audio-dialog\n",
      "models/gemini-2.5-flash-preview-native-audio-dialog-rai-v3\n",
      "models/gemini-2.5-flash-exp-native-audio-thinking-dialog\n",
      "models/gemini-2.0-flash-live-001\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# Load your key\n",
    "_ = load_dotenv(find_dotenv())\n",
    "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "\n",
    "# List available models\n",
    "models = genai.list_models()\n",
    "\n",
    "for model in models:\n",
    "    print(model.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e0843d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
